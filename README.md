# End-to-End Dockerized E-Commerce ETL Pipeline

## ğŸ“Œ Project Overview
This project demonstrates an **industry-level, end-to-end Data Engineering ETL pipeline** built using real-world e-commerce data. The pipeline follows best practices such as **Dockerization, configuration management, logging, retry logic, and data modeling**, and delivers insights through an interactive **Power BI dashboard**.

The goal of this project is to simulate how data is ingested, processed, stored, and visualized in a real production environment.

---

## ğŸ—ï¸ Architecture

```
Kaggle CSV Dataset
      â†“
Python ETL (Docker Container)
      â†“
PostgreSQL Data Warehouse (Docker Container)
      â†“
Power BI Dashboard
```

---

## ğŸ§° Tech Stack

- **Programming Language:** Python
- **Data Processing:** Pandas
- **Database:** PostgreSQL
- **Containerization:** Docker & Docker Compose
- **Visualization:** Power BI
- **Dataset Source:** Kaggle (Amazon E-Commerce Products Dataset)

---

## ğŸ“‚ Project Structure

```
ecommerce_etl_project/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ etl.py          # Main ETL pipeline
â”‚   â”œâ”€â”€ config.py       # Configuration management
â”‚   â””â”€â”€ logger.py       # Logging setup
â”œâ”€â”€ data/
â”‚   â””â”€â”€ amazon_products.csv
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql      # Star schema (optional)
â”œâ”€â”€ powerbi/
â”‚   â””â”€â”€ dashboard.pbix
â””â”€â”€ README.md
```

---

## ğŸ”„ ETL Pipeline Details

### 1ï¸âƒ£ Extract
- Reads raw CSV data downloaded from Kaggle
- Performs schema and basic validation checks

### 2ï¸âƒ£ Transform
- Handles missing values
- Cleans and standardizes columns
- Prepares data for analytical use

### 3ï¸âƒ£ Load
- Loads transformed data into PostgreSQL
- Uses Dockerized database for consistency

---

## âš™ï¸ Key Features

- âœ… Fully Dockerized ETL pipeline
- âœ… PostgreSQL data warehouse
- âœ… Retry logic for database connection
- âœ… Centralized configuration management
- âœ… Structured logging for production readiness
- âœ… Power BI dashboard for business insights

---

## â–¶ï¸ How to Run the Project

### Prerequisites
- Docker Desktop (Running)
- Git
- Power BI Desktop (for visualization)

### Steps

1. Clone the repository
```bash
git clone <your-github-repo-url>
cd ecommerce_etl_project
```

2. Run the ETL pipeline using Docker Compose
```bash
docker compose -f docker/docker-compose.yml up --build
```

3. Verify data in PostgreSQL
```sql
SELECT COUNT(*) FROM fact_sales;
```

4. Connect Power BI to PostgreSQL
- Server: `localhost`
- Database: `ecommerce`
- Username: `etl_user`
- Password: `etl_pass`

---

## ğŸ“Š Power BI Dashboard

The dashboard provides:
- Sales and product overview
- Category-level analysis
- Price and rating insights
- Interactive filters and KPIs

*(Dashboard screenshots can be added here)*

---

## ğŸ§  Learnings & Skills Demonstrated

- Data Engineering ETL workflows
- Docker & container orchestration
- Relational data modeling
- SQL and PostgreSQL
- Business Intelligence with Power BI
- Writing production-ready Python code

---

## ğŸš€ Future Enhancements

- Add Apache Airflow for orchestration
- Implement incremental data loading
- Deploy on cloud (AWS/GCP)
- Add automated data quality checks

---

## ğŸ‘¤ Author

**Muhammad Zaid**  
Aspiring Data Engineer  

- GitHub: https://github.com/<your-username>
- LinkedIn: https://linkedin.com/in/<your-profile>

---

## â­ If you find this project useful, please give it a star!
